---
title: "Análise de Dados"
author: "Edilton Brandão"
date: "27 de junho de 2023"
output:
  html_document
---

### Visualizando os dados

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
Sys.setlocale(category = "LC_ALL", locale = "pt_BR.UTF-8")

```

```{r, echo = TRUE, message=FALSE}
# Carregar pacotes necessários
library(MASS)
library(ggplot2)
library(tidyverse)
library(skimr)
library(GGally)
library(pROC)
library(corrplot)
library(fastDummies)
```

```{r dados}
# importando os dados
data = read_delim("data/student-mat.csv", delim = ";")


# dividindo os dados em um conjunto de treinamento e outro de previsões
set.seed(123)  # para reprodutibilidade

# Cria um vetor booleano (TRUE/FALSE) para usar como índice
# A função sample() é usada para criar uma amostra aleatória
split_index <- sample(2, size = nrow(data_mat), replace = TRUE, prob = c(0.8, 0.2)) == 1



# Cria o conjunto de teste
test_data <- data[!split_index, ]

# Cria o conjunto de treinamento
data <- data[split_index, ]



summary_data <- function(df) {
  df_summary <- data.frame(
    "Total Observations" = sapply(df, function(x) length(x)),
    "Missing Values" = sapply(df, function(x) sum(is.na(x))),
    "Unique Values" = sapply(df, function(x) length(unique(x))),
    "Data Type" = sapply(df, function(x) class(x)[1]),
    "Example Value" = sapply(df, function(x) x[1])
  )
  return(df_summary)
}

summary_data(data)



```

### Organizando os dados

Aqui vamos criar uma outra versão dos dados mas com as variáveis categóricas codificadas.

```{r organizando os dados}
# criando a coluna da média das três avaliações
data$GF <- (data$G1 + data$G2 + data$G3)/3


# ( One hot encoding ) codificando as variáveis categóricas

# Converte as variáveis ​​de caractere em fatores
data[] <- lapply(data, function(x) if(is.character(x)) as.factor(x) else x)
# Selecionando apenas as variáveis ​​categóricas
category_df <- data[, sapply(data, is.factor)]
# Use dummy_cols para criar dummies para todas as categorias
dummy_df <- fastDummies::dummy_cols(data, select_columns = names(category_df))
# criando um novo dataframe
dummy_df <- dummy_df[, (ncol(data) + 1):ncol(dummy_df)]
# Selecionando as variáveis numéricas do dataframe original
numeric_df <- data[, sapply(data, is.numeric)]

# Combina o dataframe de variáveis numéricas com o dataframe de variáveis categóricas codificadas
final_df <- cbind(numeric_df, dummy_df)
# removendo colunas desnecessárias
final_df <- subset(final_df, select = -c(G1, G2, G3, address_U, address_R))

```

### Analisando relacionamento x GF

Analisando a distribuição de nossa variável de interesse.

```{r}
# Criar um histograma da variável GF
hist(data$GF, xlab = "Notas (GF)", ylab = "Frequência", main = "Histograma das Notas finais (GF)")
```

Interessante, parece seguir uma distribuição normal.

```{r}
data %>%
  count(romantic) %>%
  ggplot(aes(x = "", y = n, fill = romantic)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y") +
  theme_void() +
  geom_text(aes(label = paste0(round(n/sum(n)*100), "%")), position = position_stack(vjust = 0.5)) +
  labs(title="Proporção de estudantes que namoram")
```

```{r}
ggplot(data, aes(x = sex, fill = romantic)) +
  geom_bar(position = "dodge") +
  labs(title="Quantidade de meninos e meninas que estão em um relacionamento")
```

Observa-se que a quantidade de estudantes solteiros é mais do que o dobro da quantidade de estudantes que estão em um relacionamento.

```{r}
ggplot(data, aes(x=romantic, y=GF, fill=romantic)) +
  geom_boxplot() +
  labs(title="Distribuição das notas finais por status de relacionamento", x="Status do Relacionamento", y="Nota Final")

```

```{r}
# Definir cores
colors <- c("yes" = "blue", "no" = "red")

# Plotar
ggplot(data, aes(x=GF, fill=romantic)) +
  geom_density(alpha = 0.4) +
  scale_fill_manual(values = colors) +
  theme_minimal() +
  labs(x = "Nota Final (GF)", 
       y = "Densidade", 
       fill = "Romance",
       title = "Distribuição da nota final por status de relacionamento") +
  theme(plot.title = element_text(hjust = 0.5)) # Centralizar título

```

Observando esse último gráfico, nota-se que a média das notas de estudantes que estão em um relacionamento é maior do que daqueles que não estão. No entanto, podemos observar que a distribuição do gráfico azul (estudantes que estão em um relacionamento) tem uma "cauda" mais pesada à esquerda, enquanto no gráfico vermelho ocorre exatamente o contrário. Logo, não conseguimos ainda tirar muitas conclusões sobre esses dados, pois as médias podem ser influenciados por valores extremos que não conseguimos observar aqui.

```{r}
ggplot(data, aes(x=GF)) + 
  geom_histogram(aes(y=after_stat(density)), bins=30, fill="skyblue", color="black") +
  geom_density(alpha=.2, fill="red") +
  facet_grid(sex ~ romantic) +
  labs(title="Distribuição da nota final por Sexo e Status de Relacionamento",
       x="Nota Final",
       y="Densidade") +
  theme_minimal()
```

Aqui observamos que para ambos os sexos, a distribuição de notas para alunos que namoram tem uma "cauda mais fina" no lado direito do gráfico (notas mais altas) e o contrário ocorre para alunos que não namoram. Isso significa que os alunos que não namoram tendem a tirar as notas mais altas.

### Analisando a influencia de outras variáveis

Antes de fazer a correlação vamos relembrar do novo conjunto de dados *final_df* que criamos utilizando a técnica One hot encoding para transformar cada variável categórica em uma variável binária

```{r}
# visualizando as variáveis categóricas codificadas
head(dummy_df, n = 5)
```

```{r}

# pegando as variáveis mais correlacionadas em valor absoluto
most_correlated <- cor(final_df)[, 'GF'] %>% abs() %>% sort(decreasing = TRUE)
correlation_df <- data.frame(Variable = names(most_correlated), 
                             Correlation = most_correlated)

# pegando as 20 variáveis mais correlacionadas
top_20 <- correlation_df$Variable[1:20]

# criando uma matriz de correlação apenas para essas variáveis
correlation_matrix <- cor(final_df[,top_20])

# visualizando as correlações
corrplot(correlation_matrix, method="color")


```

**Número de reprovações anteriores afeta as notas atuais?**

```{r}
ggplot(data, aes(x=GF)) + 
  geom_histogram(aes(y=after_stat(density)), bins=30, fill="skyblue", color="black") +
  geom_density(alpha=.2, fill="red") +
  facet_grid(sex ~ failures) +
  labs(title="Distribuição da nota final por sexo e reprovações",
       x="Nota Final",
       y="Densidade") +
  theme_minimal()
```

Em ambos sexos, observa-se que as notas dos alunos que mais reprovaram em anos anteriores estão distribuídas nas notas mais baixas.

**Educação dos pais importam?**\

```{r}
# Reformata os dados para long format
long_df <- reshape2::melt(data, id.vars = "GF", measure.vars = c("Medu", "Fedu"), variable.name = "ParentEducation", value.name = "EducationLevel")

# Cria o gráfico de dispersão com facet_grid
ggplot(long_df, aes(x = EducationLevel, y = GF)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE, color = "red") +
  facet_grid(. ~ ParentEducation) +
  labs(x = "Nível de Educação do Pai/Mãe", y = "Nota Final") +
  theme_minimal() +
  ggtitle("Gráfico de Dispersão: Nota Final vs Nível de Educação do Pai/Mãe")



```

Observa-se que o nível de educação dos pais está positivamente relacionado ao desempenho escolar dos filhos. Pais com níveis mais altos de educação podem influenciar positivamente o aprendizado de seus filhos.

**Vontade de fazer ensino superior influencia na nota final?**

```{r}
ggplot(data, aes(x = higher, y = GF, fill = higher)) +
  geom_boxplot() +
  labs(x = "Deseja prosseguir para o ensino superior", 
       y = "Nota Final", 
       fill = "Deseja prosseguir para o ensino superior") +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal() +
  ggtitle("Distribuição das notas com base no desejo de prosseguir para o ens.superior")



```

Realmente, é de se esperar que estudantes que desejam cursar um ensino superior estejam mais motivados a estudar e consequentemente tendem a tira as melhores notas.

**Sair com os amigos afeta o desempenho acadêmico?**

```{r}
ggplot(data, aes(x = goout, y = GF)) +
  geom_point(aes(color = sex)) +
  geom_smooth(method = lm, se = FALSE, color = "red") +
  labs(x = "Saindo com os amigos", y = "Nota Final") +
  theme_minimal() +
  ggtitle("Sair com os amigos vs Nota final")

```

Faz sentido, pois sair com os amigos pode diminuir o tempo para se dedicar aos estudos.

**E em relação a beber nos fins de semana?**

```{r}
ggplot(data, aes(x = Walc, y = GF)) +
  geom_point(aes(color = sex)) +
  geom_smooth(method = lm, se = FALSE, color = "red") +
  labs(x = "Beber no fim de semana", y = "Nota Final") +
  theme_minimal() +
  ggtitle("Beber no fim de semana vs Nota final")

```

Novamente, nenhum resultado surpreendente. Bebidas álcoolicas e ressaca impactam negativamente na concentração dos estudantes.

**Analisando a influência do tempo de estudo**

```{r}
ggplot(data, aes(x = studytime, y = GF)) +
  geom_point(aes(color = sex)) +
  geom_smooth(method = lm, se = FALSE, color = "red") +
  labs(x = "Tempo de estudo", y = "Nota Final") +
  theme_minimal() +
  ggtitle("Tempo de estudo vs Nota final")

```

**Suporte educacional extra**

```{r}
ggplot(data, aes(x = schoolsup, y = GF, fill = schoolsup)) +
  geom_boxplot() +
  labs(x = "Suporte educacional extra", 
       y = "Nota Final", 
       fill = "Suporte educacional extra") +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal() +
  ggtitle("Suporte educacional extra vs Notas")


```

```{r}
ggplot(data, aes(x=GF)) + 
  geom_histogram(aes(y=after_stat(density)), bins=60, fill="skyblue", color="black") +
  geom_density(alpha=.2, fill="red") +
  facet_grid(. ~ schoolsup) +
  labs(title="Suporte educacional extra vs Notas",
       x="Nota Final",
       y="Densidade") +
  theme_minimal()
```

Observa-se que alunos que recebem suporte educacional extra não necessariamente são os alunos com as melhores notas, mas pelo menos eles tendem a não tirar notas extremamente baixas (menor que 5).

### Testando modelos

Vamos iniciar testando o primeiro modelo, que inclui as variáveis 'failures', 'Medu', 'higher' e 'romantic' como preditoras.

-   'failures': Representa o número de reprovações que o aluno teve em disciplinas anteriores. Essa variável pode indicar o impacto negativo das reprovações no desempenho acadêmico atual.

-   'Medu': Refere-se à educação da mãe do aluno, medida em anos de estudo. Essa variável pode capturar a influência do nível de educação materna no desempenho acadêmico dos alunos.

-   'higher': Indica se o aluno tem a aspiração de cursar o ensino superior. Essa variável pode refletir a motivação e o comprometimento do aluno com seus estudos, o que pode impactar positivamente o desempenho acadêmico.

-   'romantic': Representa o status do relacionamento romântico do aluno. Essa variável pode desempenhar um papel na vida pessoal e emocional dos estudantes, potencialmente afetando seu desempenho acadêmico.

```{r}
modelo1 <- lm(GF ~ failures	+	Medu +	higher  +	romantic , data)
summary(modelo1)
```

Nota-se que as variáveis 'higher' e 'romantic' não tiveram um impacto significativo no desempenho acadêmico devido ao p-valor alto associado a elas. Por isso, decidimos substituir 'higher' por 'goout', que representa o quão o aluno sai com os amigos. Com essa modificação, vamos investigar se essa variável tem alguma relação significativa com o desempenho acadêmico dos alunos.

```{r}
modelo2 <- lm(GF ~ failures	+ Medu + goout + romantic , data)
summary(modelo2)

```

Nota-se que 'goout' teve uma relação pouca significativa com o desempenho acadêmico. Decidimos, então, adicionar uma interação entre 'goout' e 'Walc', que representa o consumo de álcool nos fins de semana, e também incluímos uma interação entre 'Medu' e 'famsup', que reflete a educação da mãe e o suporte educacional adicional. Acreditamos que a educação da mãe possa influenciar a propensão de fornecer mais meios de suporte educacional extra ao filho. Adcionamos também studytime para analisar o efeito do tempo de estudo.

```{r}
modelo3 <- lm(GF ~ failures + Medu*famsup + studytime + romantic + Walc*goout, data)
summary(modelo3)

```

Modelo apresentou melhoria no R-quadrado, mas os coeficientes não estão significativos. Vamos testar outro modelo.

```{r}
modelo4 <- lm(GF ~ failures	+ Medu + higher + romantic + Walc*goout, data)
summary(modelo4)

```

R-quadrado, piorou. Vamos fazer outra abordagem.

```{r}
modelo5 <- lm(GF ~ failures	+ Medu*higher + romantic + Walc*goout, data)
summary(modelo5)
```

Parece que a educação da mãe combinado com a vontade do aluno de querer fazer um curso superior tem um efeito significativo em nosso modelo. Vamos manter essa relação e testar novas possibilidades.

```{r}
modelo6 <- lm(GF ~ failures + Medu*higher + schoolsup + romantic + Walc*goout, data)
summary(modelo6)

```

Nosso R-square teve uma ótima melhoria, e a variável schoolsup parece ter um p-valor significativo. Vamos fazer uma comparação entre esses modelos e ver qual está se saindo melhor.

```{r}
# função de calcular o RMSE
rmse <- function(error) sqrt(mean(error^2))

# dataframe com as medidas de avaliação de modelo
resultado <- data.frame(
  Model = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5", "Model 6"),
  R_squared = c(summary(modelo1)$r.squared, summary(modelo2)$r.squared, summary(modelo3)$r.squared, summary(modelo4)$r.squared, summary(modelo5)$r.squared, summary(modelo6)$r.squared),
  AIC = c(AIC(modelo1), AIC(modelo2), AIC(modelo3), AIC(modelo4), AIC(modelo5), AIC(modelo6)),
  RMSE = c(rmse(modelo1$residuals), rmse(modelo2$residuals), rmse(modelo3$residuals), rmse(modelo4$residuals), rmse(modelo5$residuals), rmse(modelo6$residuals))
)

print(resultado)




```

Observamos que o p-valor alto da variável 'romantic' foi um resultado consistente em todos os modelos testados. Portanto, decidimos encerrar a análise nesse ponto, uma vez que identificamos esse padrão comum. Essa observação é relevante para o foco principal do trabalho, e acredito ser não necessário continuar testando modelos adicionais.

```{r}

# Obter o coeficiente estimado de uma variável específica
coeficiente_estimado <- coef(modelo6)["romanticyes"]

# Calcular o intervalo de confiança para o coeficiente estimado
intervalo_confianca <- confint(modelo6)["romanticyes", ]

# Imprimir o coeficiente estimado e o intervalo de confiança
cat("Coeficiente estimado de romantic:", coeficiente_estimado, "\n")
cat("Intervalo de confiança para o coeficiente estimado de romantic:", intervalo_confianca, "\n")
```

**Vamos observar o histograma dos resíduos para ver se eles estão cumprindo o pressuposto do nosso modelo de regressão: comportando como uma distribuição normal**


```{r}
# Criar uma função para calcular resíduos
get_residuals <- function(model, name) {
  data.frame(
    Model = name,
    Residuals = residuals(model)
  )
}

# Calcular resíduos para cada modelo
residuos <- rbind(
  get_residuals(modelo1, "Model 1"),
  get_residuals(modelo2, "Model 2"),
  get_residuals(modelo3, "Model 3"),
  get_residuals(modelo4, "Model 4"),
  get_residuals(modelo5, "Model 5"),
  get_residuals(modelo6, "Model 6")
)

# Criar histograma
ggplot(residuos, aes(x = Residuals)) +
  geom_histogram(binwidth = .5, color = "black", fill = "white") +
  facet_wrap(~ Model, scales = "free") +
  theme_bw() +
  labs(x = "Resíduos", y = "Frequência", title = "Histogramas de Resíduos")

```

Aparentemente os resíduos estão seguindo uma distribução normal o que é ótimo para o nosso suposição de nosso modelo.

**Concluímos**

Dentre os modelos, o que apresentou melhor performance foi o **modelo6**, que inclui uma interação entre Medu e schoolsup e goout e Walc, pois possui um melhor AIC, RMSE e um melhor R-quadrado.


### Predições

```{r}
predicoes <- predict(modelo6, newdata = test_data)

test_data$GF <- (test_data$G1 + test_data$G2 + test_data$G3 )/3

plot(test_data$GF, predicoes, xlab = "Valores reais", ylab = "Previsões", main = "Valores reais vs Previsões")
abline(0, 1)  # Adiciona uma linha y = x para referência


```
```{r}
residuos <- residuals(modelo6)
plot(residuos, ylab = "Resíduos", main = "Gráfico de Resíduos")
abline(h = 0)  # Adiciona uma linha horizontal em y = 0

```

